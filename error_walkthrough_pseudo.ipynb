{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo code to show process of computing RV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = 65\n",
    "excalibur_mask  = fits_data['EXCALIBUR_MASK'][order]\n",
    "y           = fits_data['spectrum'][order][excalibur_mask]\n",
    "y_err       = fits_data['uncertainty'][order][excalibur_mask]\n",
    "continuum   = fits_data['continuum'][order][excalibur_mask]\n",
    "x           = fits_data['BARY_EXCALIBUR'][order][excalibur_mask]\n",
    "\n",
    "# Normalize intensity by continuum \n",
    "y = y/continuum\n",
    "y_err = y_err/continuum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute shift for one match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1, y1, y1_err : comes from feature1\n",
    "# x2, y2, y2_err : comes from feature2\n",
    "\n",
    "# Interp first file\n",
    "f1 = interp1d(x1, y1, kind='cubic', fill_value=\"extrapolate\")\n",
    "f1_upper_err = interp1d(x1, y1 + y1_err, kind='cubic', fill_value=\"extrapolate\")\n",
    "f1_lower_err = interp1d(x1, y1 - y1_err, kind='cubic', fill_value=\"extrapolate\")\n",
    "\n",
    "# ChiSquare fit model:\n",
    "def model_chi2(A):\n",
    "\n",
    "    # Interpolate template\n",
    "    interp_x2 = x2 * (1 + A/c)                                                  # Wavelengths are be stretched by a factor of (1 + v/c)\n",
    "    f2 = interp1d(interp_x2, y2, kind='cubic', fill_value=\"extrapolate\")\n",
    "\n",
    "    # Find common x-range\n",
    "    xmin = max([min(x1), min(interp_x2)])\n",
    "    xmax = min([max(x1), max(interp_x2)])\n",
    "    xnewCommon = np.linspace(xmin, xmax, interp_size)\n",
    "    \n",
    "    # Evaluate interpolation\n",
    "    ynew1 = f1(xnewCommon)\n",
    "    ynew2 = f2(xnewCommon)\n",
    "\n",
    "    # Evalute error interpolation\n",
    "    ynew1_upper_err = f1_upper_err(xnewCommon)\n",
    "    ynew1_lower_err = f1_lower_err(xnewCommon)\n",
    "    ynew1_upper_err_abs = np.abs(ynew1 - ynew1_upper_err)\n",
    "    ynew1_lower_err_abs = np.abs(ynew1 - ynew1_lower_err)\n",
    "    ynew1_err = np.mean([ynew1_upper_err_abs, ynew1_lower_err_abs], axis=0) # pairwise mean \n",
    "    \n",
    "    # Compute chi2\n",
    "    chi2 = np.sum(((ynew1 - ynew2) / ynew1_err)**2)\n",
    "    return chi2\n",
    "model_chi2.errordef = 1\n",
    "    \n",
    "# Init value\n",
    "A_init = (peak1 / peak2 - 1 ) * c # shift between the two peaks\n",
    "\n",
    "# Compute bounds on A\n",
    "x1_min, x1_max = min(x1), max(x1)\n",
    "A_lower_bound = (x1_min / peak2 - 1 ) * c\n",
    "A_upper_bound = (x1_max / peak2 - 1 ) * c\n",
    "\n",
    "minuit = Minuit(model_chi2, A=A_init)\n",
    "minuit.limits[\"A\"] = (A_lower_bound, A_upper_bound)\n",
    "minuit.migrad()\n",
    "\n",
    "# Results\n",
    "valid = minuit.valid\n",
    "shift_min_final = minuit.values['A']            # value used\n",
    "shift_min_final_err = minuit.errors['A']        # error used\n",
    "\n",
    "forced = minuit.fmin.has_made_posdef_covar\n",
    "at_limit = minuit.fmin.has_parameters_at_limit\n",
    "\n",
    "if forced or at_limit:\n",
    "    valid = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding overall difference per match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mean(x, errors):\n",
    "    m1 = np.sum([x/s**2 for x, s in zip(x, errors)])\n",
    "    m2 = np.sum([1/(x**2) for x in errors])\n",
    "    mean = m1/m2\n",
    "    err = np.sqrt(1/np.sum([1/(x**2) for x in errors]))\n",
    "    return (mean, err)\n",
    "\n",
    "\n",
    "# shifts, shifts_err are list of results for all matches in one observation comparison\n",
    "shift_mean, shift_mean_err = weighted_mean(shifts, shifts_err)\n",
    "median = np.median(shifts)\n",
    "\n",
    "# but I use \n",
    "median, shift_mean_err\n",
    "# and not the weighted mean, because it is influced my outliers too much. What is the error on the median? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values _median_ and _shift_mean_err_ are then put into the matrix for all observation comparisons (better word?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix reduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_chi2(*V):\n",
    "    V = np.asarray([*V])\n",
    "    res = []\n",
    "    size = diff_matrix.shape[0] \n",
    "    for x in np.arange(size):\n",
    "        # for y in np.arange(x, size - 1):\n",
    "        for y in np.arange(x, size):\n",
    "            if x != y:\n",
    "                diff_matrix[x, y]\n",
    "                V[x]\n",
    "                V[y]\n",
    "                res.append(((diff_matrix[x, y] - (V[x] - V[y])) / diff_matrix_err[x, y])**2)\n",
    "    chi2 = np.sum(res)\n",
    "    return chi2\n",
    "model_chi2.errordef = 1\n",
    "\n",
    "# Use list of zeros as init values (len of the number of observations)\n",
    "init_values = np.zeros(diff_matrix.shape[0])\n",
    "\n",
    "minuit = Minuit(model_chi2, *init_values)\n",
    "m = minuit.migrad()\n",
    "\n",
    "final_shifts = minuit.values[:]             # final value\n",
    "final_shifts_err = minuit.errors[:]         # final error"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
